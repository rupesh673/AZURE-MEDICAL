{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Microsoft AI Rangers Demo\n",
        "# Large Scale Image Classification\n",
        "__X-Ray Classification using CheXpert__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"images/dp-chexpert.png\" width=800 />\n",
        "\n",
        "### Goal\n",
        "The goal of this notebook is demonstrate feasibility of large scale multi-label image classification from radiographs using the [Automated Machine Learning](https://learn.microsoft.com/en-us/azure/machine-learning/concept-automated-ml) feature of Azure Machine Learning. For this, we are using [CheXpert:](https://stanfordmlgroup.github.io/competitions/chexpert/) a large chest X-Ray dataset. Given that the original size of CheXpert is ~400GB, we will use the small version (images resized) which is ~11GB and to explore model performance, we will use a small dataset (~250 images).\n",
        "\n",
        "### Steps\n",
        "\n",
        "1. Upload data (small dataset) to the Datastore through an AML Data asset (URI Folder)\n",
        "2. Create an MLTable from labeled training data in JSONL format\n",
        "3. Set AutoML Run\n",
        "4. Configure parameters and run\n",
        "\n",
        "At the end, we show results using CheXpert standard image size (no resizing).\n",
        "\n",
        "This notebook was developed and tested using an Azure ML STANDARD_D13_V2 CPU [compute instance](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-create-manage-compute-instance?tabs=python) and an Azure ML [Python SDK v2](https://learn.microsoft.com/en-us/azure/machine-learning/concept-v2).\n",
        "\n",
        "As with previous examples, having Azure account is a prerequisite. Once you have it, please set up an Azure ML Workspace and either create a new notebook or import this one there. You can follow official documentation for more details: https://learn.microsoft.com/en-us/azure/machine-learning/how-to-run-jupyter-notebooks "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# 1. Upload data (small dataset) to the Datastore through an AML Data asset (URI Folder)\n",
        "\n",
        "Since AutoML relies on AzureML experiment management infrastructure, we need to stage our data in the cloud first. \n",
        "\n",
        "## Download and extract CheXpert\n",
        "The dataset is available for download [here](https://stanfordmlgroup.github.io/competitions/chexpert/). After filling out the form you will receive an automated email from Stanford which will have a link to both full and downsampled dataset in it. We have downloaded the dataset from above url and unzipped the images files into the following structure:\n",
        "\n",
        "<img src=\"images/dp-chexpert-file-structure.png\" width=200 />\n",
        "\n",
        "Run the following cell (by replacing LINK_TO_FILE with the link you receive in the email) if you want to update and unzip automatically.\n",
        "\n",
        "> `NOTICE`: \n",
        "> Chexpert dataset contains images encoded as grayscale JPEGs. Since you are here, you probably know that real-world medical images come in DICOM format which is capable of much higher intensity range than what the 8bit grayscale that JPEG can provide is capable of. At the moment of writing, however, AutoML only supports the common 2D RGB image formats such as BMP, JPEG or PNG. You would have to convert your DICOMs into one of those, applying appropriate window width/window level transforms for best results. Unfortunately, if you are looking at working with 3D or 4D data such as CT, MR, fMRI, etc, you would either need to cast your task so that it can be inferred from independent 2D slices or use more advanced specialized frameworks such as Microsoft Research's [InnerEye Deep Learning SDK](https://github.com/microsoft/InnerEye-DeepLearning)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# remove files from /tmp to avoid potential overlap from previous runs\n",
        "!rm /tmp/CheXpert-v1.0-small.zip\n",
        "!rm -r /tmp/CheXpert-v1.0-small\n",
        "\n",
        "# Download the small version of the dataset\n",
        "!wget \"LINK_TO_FILE\" -P /tmp\n",
        "!unzip -q /tmp/CheXpert-v1.0-small.zip -d /tmp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract a small sample dataset (~250 images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1668731508346
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os, shutil\n",
        "\n",
        "def chexpert_sampler(base_dir,chexpert_original_dir,chexpert_new_dir,n_train, n_valid):\n",
        "\n",
        "    pathologies = ['Cardiomegaly', 'Edema', 'Consolidation', 'Atelectasis', 'Pleural Effusion']\n",
        "    df_train = pd.read_csv( base_dir + chexpert_original_dir + '/train.csv')\n",
        "    df_valid = pd.read_csv( base_dir + chexpert_original_dir + '/valid.csv')\n",
        "\n",
        "    df_train = df_train[df_train['Frontal/Lateral'] == 'Frontal']  \n",
        "    df_valid = df_valid[df_valid['Frontal/Lateral'] == 'Frontal']\n",
        "\n",
        "    print(df_train.columns[7],df_train.columns[10],df_train.columns[11],df_train.columns[13],df_train.columns[15])\n",
        "    df_train_sample = pd.concat([df_train[df_train.Cardiomegaly==1].sample(n=n_train), df_train[df_train.Edema==1].sample(n=n_train), df_train[df_train.Consolidation==1].sample(n=n_train), \\\n",
        "        df_train[df_train.Atelectasis==1].sample(n=n_train), df_train[df_train['Pleural Effusion']==1].sample(n=n_train)  ] )\n",
        "    df_train_sample.reset_index(drop=True,inplace=True)        \n",
        "\n",
        "    df_valid_sample = pd.concat([df_valid[df_valid.Cardiomegaly==1].sample(n=n_valid), df_valid[df_valid.Edema==1].sample(n=n_valid), df_valid[df_valid.Consolidation==1].sample(n=n_valid), \\\n",
        "        df_valid[df_valid.Atelectasis==1].sample(n=n_valid), df_valid[df_valid['Pleural Effusion']==1].sample(n=n_valid)  ] )\n",
        "    df_valid_sample.reset_index(drop=True,inplace=True)\n",
        "\n",
        "    for index, row in df_train_sample.iterrows():    \n",
        "        path_source, __   = os.path.split( base_dir + df_train_sample.loc[index, 'Path'] )\n",
        "        df_train_sample.loc[index, 'Path'] = row.Path.replace(chexpert_original_dir,chexpert_new_dir)   \n",
        "        path_target, file = os.path.split( base_dir + df_train_sample.loc[index, 'Path'] )\n",
        "        print( path_target )\n",
        "        if not os.path.isdir(path_target):\n",
        "            os.makedirs(path_target)\n",
        "        shutil.copyfile( path_source + os.sep + file, path_target + os.sep + file)\n",
        "\n",
        "    for index, row in df_valid_sample.iterrows():\n",
        "        path_source, __   = os.path.split( base_dir + df_valid_sample.loc[index, 'Path'] )\n",
        "        df_valid_sample.loc[index, 'Path'] = row.Path.replace(chexpert_original_dir,chexpert_new_dir)   \n",
        "        path_target, file = os.path.split( base_dir + df_valid_sample.loc[index, 'Path'] )\n",
        "        print( path_target )\n",
        "        if not os.path.isdir(path_target):\n",
        "            os.makedirs(path_target)\n",
        "        shutil.copyfile( path_source + os.sep + file, path_target + os.sep + file)\n",
        "\n",
        "    df_train_sample.to_csv(base_dir + os.sep + chexpert_new_dir + \"/train.csv\", index = False)\n",
        "    df_valid_sample.to_csv(base_dir + os.sep + chexpert_new_dir + \"/valid.csv\", index = False)\n",
        "\n",
        "\n",
        "base_dir                = \"/tmp/\"\n",
        "chexpert_original_dir   = \"CheXpert-v1.0-small\"\n",
        "chexpert_new_dir        = \"chexpert_small_demo\"\n",
        "chexpert_sampler(base_dir,chexpert_original_dir,chexpert_new_dir,n_train=100,n_valid=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Upload data\n",
        "\n",
        "You will be using Blob storage as the datastore in this example. Every Azure ML workspace will have a default datastore which the code below uses. You can pick a different datastore for your real-world scenario.\n",
        "\n",
        "[Check this notebook for AML data asset example.](https://github.com/Azure/azureml-examples/blob/a7f2b1894769736a2bbfcfb5c4e1d00269f8c6a6/sdk/python/assets/data/data.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1668731537320
        }
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.ml import MLClient, Input\n",
        "\n",
        "from azure.ai.ml.automl import SearchSpace, ClassificationMultilabelPrimaryMetrics\n",
        "from azure.ai.ml.sweep import (\n",
        "    Choice,\n",
        "    Uniform,\n",
        "    BanditPolicy,\n",
        ")\n",
        "\n",
        "from azure.ai.ml import automl\n",
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes, InputOutputModes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1668731540130
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found the config file in: /config.json\n"
          ]
        }
      ],
      "source": [
        "credential = DefaultAzureCredential()\n",
        "ml_client = None\n",
        "try:\n",
        "    ml_client = MLClient.from_config(credential)\n",
        "except Exception as ex:\n",
        "    print(ex)\n",
        "    # Enter details of your AML workspace\n",
        "    subscription_id = \"\"\n",
        "    resource_group = \"\"\n",
        "    workspace = \"\"\n",
        "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1668731698217
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data({'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': None, 'type': 'uri_folder', 'is_anonymous': False, 'auto_increment_version': False, 'name': 'chexpert_small_demo_asset', 'description': 'CheXpert dataset small version for demo', 'tags': {}, 'properties': {}, 'id': '/subscriptions/MY_SUBSCRIPTION/resourceGroups/MY_RESOURCEGROUP/providers/Microsoft.MachineLearningServices/workspaces/MY_WORKSPACE/data/chexpert_small_demo_asset/versions/10', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/demo6/code/Users/medical-imaging/notebooks', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f5bbc2dcb50>, 'serialize': <msrest.serialization.Serializer object at 0x7f5bbc2dc550>, 'version': '10', 'latest_version': None, 'path': 'azureml://subscriptions/MY_SUBSCRIPTION/resourcegroups/MY_RESOURCEGROUP/workspaces/MY_WORKSPACE/datastores/workspaceblobstore/paths/LocalUpload/bf6fb7b1e88207436d2a346c6bcf7ded/chexpert_small_demo/', 'datastore': None})\n",
            "\n",
            "Path to folder in Blob Storage\n",
            "azureml://subscriptions/MY_SUBSCRIPTION/resourcegroups/MY_RESOURCEGROUP/workspaces/MY_WORKSPACE/datastores/workspaceblobstore/paths/LocalUpload/bf6fb7b1e88207436d2a346c6bcf7ded/chexpert_small_demo/\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "chexpert_local_path = base_dir + chexpert_new_dir \n",
        "\n",
        "my_data = Data(\n",
        "    path=chexpert_local_path,\n",
        "    type=AssetTypes.URI_FOLDER,\n",
        "    description=\"CheXpert dataset small version for demo\",\n",
        "    name=\"chexpert_small_demo_asset\",\n",
        ")\n",
        "\n",
        "uri_folder_data_asset = ml_client.data.create_or_update(my_data)\n",
        "\n",
        "print(uri_folder_data_asset)\n",
        "print(\"\")\n",
        "print(\"Path to folder in Blob Storage\")\n",
        "print(uri_folder_data_asset.path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 2. Create an MLTable from labeled training data in JSONL format\n",
        "\n",
        "AutoML expects the mapping between data points and labels to be in a [JSONL format](https://jsonlines.org/). The following code will take in the training and validation CSVs provided by Chexpert and turn them into JSONL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1668731705190
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(500, 19)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Path</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Frontal/Lateral</th>\n",
              "      <th>AP/PA</th>\n",
              "      <th>No Finding</th>\n",
              "      <th>Enlarged Cardiomediastinum</th>\n",
              "      <th>Cardiomegaly</th>\n",
              "      <th>Lung Opacity</th>\n",
              "      <th>Lung Lesion</th>\n",
              "      <th>Edema</th>\n",
              "      <th>Consolidation</th>\n",
              "      <th>Pneumonia</th>\n",
              "      <th>Atelectasis</th>\n",
              "      <th>Pneumothorax</th>\n",
              "      <th>Pleural Effusion</th>\n",
              "      <th>Pleural Other</th>\n",
              "      <th>Fracture</th>\n",
              "      <th>Support Devices</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>chexpert_small_demo/train/patient39463/study2/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>66</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>chexpert_small_demo/train/patient17454/study8/...</td>\n",
              "      <td>Male</td>\n",
              "      <td>73</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>chexpert_small_demo/train/patient25099/study2/...</td>\n",
              "      <td>Male</td>\n",
              "      <td>64</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>AP</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>chexpert_small_demo/train/patient28255/study1/...</td>\n",
              "      <td>Female</td>\n",
              "      <td>49</td>\n",
              "      <td>Frontal</td>\n",
              "      <td>PA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Path     Sex  Age  \\\n",
              "0  chexpert_small_demo/train/patient39463/study2/...  Female   66   \n",
              "1  chexpert_small_demo/train/patient17454/study8/...    Male   73   \n",
              "2  chexpert_small_demo/train/patient25099/study2/...    Male   64   \n",
              "3  chexpert_small_demo/train/patient28255/study1/...  Female   49   \n",
              "\n",
              "  Frontal/Lateral AP/PA  No Finding  Enlarged Cardiomediastinum  Cardiomegaly  \\\n",
              "0         Frontal    AP         NaN                         NaN           1.0   \n",
              "1         Frontal    AP         NaN                         NaN           1.0   \n",
              "2         Frontal    AP         NaN                         NaN           1.0   \n",
              "3         Frontal    PA         NaN                         NaN           1.0   \n",
              "\n",
              "   Lung Opacity  Lung Lesion  Edema  Consolidation  Pneumonia  Atelectasis  \\\n",
              "0           NaN          NaN    1.0            1.0       -1.0         -1.0   \n",
              "1           NaN          NaN    1.0            NaN        NaN          NaN   \n",
              "2           NaN          NaN    NaN            1.0        NaN          1.0   \n",
              "3           1.0          NaN    NaN            0.0        NaN          1.0   \n",
              "\n",
              "   Pneumothorax  Pleural Effusion  Pleural Other  Fracture  Support Devices  \n",
              "0           0.0               1.0            NaN       NaN              1.0  \n",
              "1           NaN               NaN            NaN       NaN              1.0  \n",
              "2           0.0               1.0            NaN       NaN              1.0  \n",
              "3           0.0               0.0            NaN       NaN              1.0  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json, os\n",
        "\n",
        "df_train = pd.read_csv( chexpert_local_path + '/train.csv')\n",
        "df_train = df_train[df_train['Frontal/Lateral'] == 'Frontal']  \n",
        "\n",
        "df_valid = pd.read_csv(chexpert_local_path + '/valid.csv')\n",
        "df_valid = df_valid[df_valid['Frontal/Lateral'] == 'Frontal']  \n",
        "\n",
        "print(df_train.shape)\n",
        "df_train.head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1668731712153
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "pathologies = ['Cardiomegaly', 'Edema', 'Consolidation', 'Atelectasis', 'Pleural Effusion']\n",
        "# sample json line dictionary\n",
        "json_line_sample = {\n",
        "    \"image_url\": uri_folder_data_asset.path.replace(chexpert_new_dir+'/',\"\"),\n",
        "    \"label\": \"\"\n",
        "    }\n",
        "\n",
        "MLTable =  \\\n",
        "'''paths:\n",
        "  - file: ./MY_FILE\n",
        "transformations:\n",
        "  - read_json_lines:\n",
        "        encoding: utf8\n",
        "        invalid_lines: error\n",
        "        include_path_column: false\n",
        "  - convert_column_types:\n",
        "      - columns: image_url\n",
        "        column_type: stream_info\n",
        "'''\n",
        "\n",
        "chexpert_train_jsonl_file_name      = \"chexpert_train.jsonl\"\n",
        "chexpert_validation_jsonl_file_name = \"chexpert_validation.jsonl\"\n",
        "\n",
        "labels_chexpert_local_path          = chexpert_local_path + '/label_files/'\n",
        "\n",
        "chexpert_train_jsonl_dir_name       = chexpert_train_jsonl_file_name.replace(\".jsonl\",\"_mltable_folder\")\n",
        "chexpert_validation_jsonl_dir_name  = chexpert_validation_jsonl_file_name.replace(\".jsonl\",\"_mltable_folder\")\n",
        "\n",
        "training_mltable_path               = labels_chexpert_local_path + os.sep + chexpert_train_jsonl_dir_name\n",
        "validation_mltable_path             = labels_chexpert_local_path + os.sep + chexpert_validation_jsonl_dir_name\n",
        "\n",
        "\n",
        "for path in [labels_chexpert_local_path, training_mltable_path, validation_mltable_path]:\n",
        "    os.mkdir(path) if not os.path.exists(path) else None\n",
        "\n",
        "# Path to the training and validation files\n",
        "train_annotations_file      = labels_chexpert_local_path + os.sep + chexpert_train_jsonl_dir_name       + os.sep + chexpert_train_jsonl_file_name\n",
        "validation_annotations_file = labels_chexpert_local_path + os.sep + chexpert_validation_jsonl_dir_name  + os.sep + chexpert_validation_jsonl_file_name\n",
        "\n",
        "with open(train_annotations_file, \"w\") as train_f:\n",
        "    for idx, row in df_train.iterrows():    \n",
        "        pathology_list = [pathology for pathology in pathologies if row[pathology] == 1]\n",
        "        if len(pathology_list) == 0:\n",
        "            pathology_list.append(\"X_other\")\n",
        "        json_line = dict(json_line_sample)\n",
        "        json_line[\"image_url\"] += row.Path\n",
        "        json_line[\"label\"] = pathology_list  \n",
        "        train_f.write(json.dumps(json_line) + \"\\n\")\n",
        "\n",
        "with open(train_annotations_file.replace(chexpert_train_jsonl_file_name,\"MLTable\"), \"w\") as mltable_f:\n",
        "    mltable_f.write( MLTable.replace(\"MY_FILE\",chexpert_train_jsonl_file_name) + \"\\n\")\n",
        "\n",
        "with open(validation_annotations_file, \"w\") as validation_f:\n",
        "    for idx, row in df_valid.iterrows():\n",
        "        pathology_list = [pathology for pathology in pathologies if row[pathology] == 1]\n",
        "        if len(pathology_list) == 0:\n",
        "            pathology_list.append(\"X_other\")\n",
        "        json_line = dict(json_line_sample)\n",
        "        json_line[\"image_url\"] += row.Path\n",
        "        json_line[\"label\"] = pathology_list  \n",
        "        validation_f.write(json.dumps(json_line) + \"\\n\")\n",
        "\n",
        "with open(validation_annotations_file.replace(chexpert_validation_jsonl_file_name,\"MLTable\"), \"w\") as mltable_f:\n",
        "    mltable_f.write( MLTable.replace(\"MY_FILE\",chexpert_validation_jsonl_file_name) + \"\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1668731715395
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/azureuser/cloudfiles/code/Users/demo/chexpert_small_demo/label_files//chexpert_train_mltable_folder\n"
          ]
        }
      ],
      "source": [
        "# Training MLTable defined locally, with local data to be uploaded\n",
        "my_training_data_input = Input(type=AssetTypes.MLTABLE, path=training_mltable_path)\n",
        "\n",
        "# Validation MLTable defined locally, with local data to be uploaded\n",
        "my_validation_data_input = Input(type=AssetTypes.MLTABLE, path=validation_mltable_path)\n",
        "\n",
        "# WITH REMOTE PATH: If available already in the cloud/workspace-blob-store\n",
        "# my_training_data_input = Input(type=AssetTypes.MLTABLE, path=\"azureml://datastores/workspaceblobstore/paths/vision-classification/train\")\n",
        "# my_validation_data_input = Input(type=AssetTypes.MLTABLE, path=\"azureml://datastores/workspaceblobstore/paths/vision-classification/valid\")\n",
        "\n",
        "print(training_mltable_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Compute target setup\n",
        "You need to provide a [Compute Target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) that will be used for your AutoML model training. AutoML models for image tasks require GPU SKUs and support NC and ND families. We recommend using the NCsv3-series (with v100 GPUs) for faster training. Using a compute target with a multi-GPU VM SKU will leverage the multiple GPUs to speed up training. Additionally, setting up a compute target with multiple nodes will allow for faster model training by leveraging parallelism, when tuning hyperparameters for your model. See more on the compute targets in the official documentation: https://learn.microsoft.com/en-us/azure/machine-learning/concept-compute-target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1668731720278
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing compute target.\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "from azure.core.exceptions import ResourceNotFoundError\n",
        "\n",
        "compute_name = \"gpu-cluster\"\n",
        "\n",
        "try:\n",
        "    _ = ml_client.compute.get(compute_name)\n",
        "    print(\"Found existing compute target.\")\n",
        "except ResourceNotFoundError:\n",
        "    print(\"Creating a new compute target...\")\n",
        "    compute_config = AmlCompute(\n",
        "        name=compute_name,\n",
        "        type=\"amlcompute\",\n",
        "        size=\"Standard_NC6\",\n",
        "        idle_time_before_scale_down=120,\n",
        "        min_instances=0,\n",
        "        max_instances=4,\n",
        "    )\n",
        "    ml_client.begin_create_or_update(compute_config).result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1668731725361
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# general job parameters\n",
        "exp_name = \"chexpert-demo\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 4. Configure parameters and run\n",
        "\n",
        "The key feature of AutoML is that it can sweep across a set of parameters selecting the combination that works best for your task. \n",
        "\n",
        "The configuration below uses Vision Transformer (ViT) and a variant of a ResNext (SE ResNeXt)[ (more info here)](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models?tabs=cli#supported-model-algorithms) with image resize set to 256 and image center crop set to 224. To evaluate performance, we use an [early termination policy](https://learn.microsoft.com/en-us/azure/machine-learning/v1/how-to-auto-train-image-models-v1#early-termination-policies). In larger datasets and depending on the compute budget you can specify an early termination policy such as [Median stopping](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters#median-stopping-policy).\n",
        "\n",
        "\n",
        "You can modify this configuration by adding more models and parameters to try out. See reference here: https://learn.microsoft.com/en-us/azure/machine-learning/how-to-auto-train-image-models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1668731730522
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Create the AutoML job with the related factory-function.\n",
        "\n",
        "image_classification_multilabel_job = automl.image_classification_multilabel(\n",
        "    compute=compute_name,\n",
        "    experiment_name=exp_name,\n",
        "    training_data=my_training_data_input,\n",
        "    validation_data=my_validation_data_input,\n",
        "    target_column_name=\"label\",\n",
        "    primary_metric=ClassificationMultilabelPrimaryMetrics.IOU,\n",
        "    tags={\"my_custom_tag\": \"My custom value\"},\n",
        ")\n",
        "\n",
        "image_classification_multilabel_job.set_limits(\n",
        "    timeout_minutes=60,\n",
        "    max_trials=10,\n",
        "    max_concurrent_trials=2,\n",
        ")\n",
        "\n",
        "image_classification_multilabel_job.extend_search_space(\n",
        "    [\n",
        "        SearchSpace(\n",
        "            model_name=Choice([\"vitb16r224\"]),\n",
        "            learning_rate=Uniform(0.005, 0.05),\n",
        "            number_of_epochs=Choice([15, 30]),\n",
        "            gradient_accumulation_step=Choice([1, 2]),\n",
        "        ),\n",
        "        SearchSpace(\n",
        "            model_name=Choice([\"seresnext\"]),\n",
        "            learning_rate=Uniform(0.005, 0.05),\n",
        "            # model-specific, valid_resize_size should be larger or equal than valid_crop_size\n",
        "            validation_resize_size=Choice([288, 320, 352]),\n",
        "            validation_crop_size=Choice([224, 256]),  # model-specific\n",
        "            training_crop_size=Choice([224, 256]),  # model-specific\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "image_classification_multilabel_job.set_sweep(\n",
        "    sampling_algorithm=\"Random\",\n",
        "    early_termination=BanditPolicy(\n",
        "        evaluation_interval=2, slack_factor=0.2, delay_evaluation=6\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1668731740436
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\u001b[32mUploading chexpert_validation_mltable_folder (0.02 MBs):   0%|          | 0/16947 [00:00<?, ?it/s]\r\u001b[32mUploading chexpert_validation_mltable_folder (0.02 MBs): 100%|██████████| 16947/16947 [00:00<00:00, 585283.04it/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created job: ImageClassificationMultilabelJob({'log_verbosity': <LogVerbosity.INFO: 'Info'>, 'target_column_name': 'label', 'validation_data_size': None, 'task_type': <TaskType.IMAGE_CLASSIFICATION_MULTILABEL: 'ImageClassificationMultilabel'>, 'training_data': {'type': 'mltable', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/bf6fb7b1e88207436d2a346c6bcf7ded/chexpert_train_mltable_folder'}, 'validation_data': {'type': 'mltable', 'path': 'azureml://datastores/workspaceblobstore/paths/LocalUpload/efe13e0cf86a8b49b6fc8b98f6585b04/chexpert_validation_mltable_folder'}, 'test_data': None, 'environment_id': None, 'environment_variables': None, 'outputs': {}, 'type': 'automl', 'status': 'NotStarted', 'log_files': None, 'name': 'gentle_carpet_grpm1rfbw3', 'description': None, 'tags': {'my_custom_tag': 'My custom value'}, 'properties': {}, 'id': '/subscriptions/MY_SUBSCRIPTION/resourceGroups/MY_RESOURCEGROUP/providers/Microsoft.MachineLearningServices/workspaces/MY_WORKSPACE/jobs/gentle_carpet_grpm1rfbw3', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/demo6/code/Users/medical-imaging/notebooks', 'creation_context': <azure.ai.ml._restclient.v2022_10_01_preview.models._models_py3.SystemData object at 0x7f5bac17d750>, 'serialize': <msrest.serialization.Serializer object at 0x7f5bac17ee90>, 'inputs': {}, 'display_name': 'gentle_carpet_grpm1rfbw3', 'experiment_name': 'chexpert-demo', 'compute': 'gpu-cluster', 'services': {'Tracking': <azure.ai.ml._restclient.v2022_10_01_preview.models._models_py3.JobService object at 0x7f5bac17c2e0>, 'Studio': <azure.ai.ml._restclient.v2022_10_01_preview.models._models_py3.JobService object at 0x7f5bac17da20>}, 'resources': <azure.ai.ml._restclient.v2022_10_01_preview.models._models_py3.JobResourceConfiguration object at 0x7f5bac17c070>, 'identity': None, 'limits': <azure.ai.ml.entities._job.automl.image.image_limit_settings.ImageLimitSettings object at 0x7f5bae36ffa0>, 'sweep': <azure.ai.ml.entities._job.automl.image.image_sweep_settings.ImageSweepSettings object at 0x7f5bae36fa90>, 'training_parameters': None, 'search_space': [<azure.ai.ml.entities._job.automl.image.image_classification_search_space.ImageClassificationSearchSpace object at 0x7f5bbc2df490>, <azure.ai.ml.entities._job.automl.image.image_classification_search_space.ImageClassificationSearchSpace object at 0x7f5bac17d5d0>], 'primary_metric': <ClassificationMultilabelPrimaryMetrics.IOU: 'IOU'>})\n"
          ]
        }
      ],
      "source": [
        "# Submit the AutoML job\n",
        "returned_job = ml_client.jobs.create_or_update(\n",
        "    image_classification_multilabel_job\n",
        ")  # submit the job to the backend\n",
        "\n",
        "print(f\"Created job: {returned_job}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1668734349405
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RunId: gentle_carpet_grpm1rfbw3\n",
            "Web View: https://ml.azure.com/runs/gentle_carpet_grpm1rfbw3?wsid=/subscriptions/MY_SUBSCRIPTION/resourcegroups/MY_RESOURCEGROUP/workspaces/MY_WORKSPACE\n",
            "\n",
            "Execution Summary\n",
            "=================\n",
            "RunId: gentle_carpet_grpm1rfbw3\n",
            "Web View: https://ml.azure.com/runs/gentle_carpet_grpm1rfbw3?wsid=/subscriptions/MY_SUBSCRIPTION/resourcegroups/MY_RESOURCEGROUP/workspaces/MY_WORKSPACE\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ml_client.jobs.stream(returned_job.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1668734350244
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>chexpert-demo</td><td>gentle_carpet_grpm1rfbw3_HD</td><td>sweep</td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/gentle_carpet_grpm1rfbw3_HD?wsid=/subscriptions/MY_SUBSCRIPTION/resourcegroups/MY_RESOURCEGROUP/workspaces/MY_WORKSPACE&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
            ],
            "text/plain": [
              "SweepJob({'type': 'sweep', 'status': 'Completed', 'log_files': None, 'name': 'gentle_carpet_grpm1rfbw3_HD', 'description': None, 'tags': {'_aml_system_azureml.automlComponent': 'AutoML', '_aml_system_max_concurrent_jobs': '2', 'max_concurrent_jobs': '2', '_aml_system_max_total_jobs': '10', 'max_total_jobs': '10', '_aml_system_max_duration_minutes': '60', 'max_duration_minutes': '60', '_aml_system_policy_config': '{\"name\":\"Bandit\",\"properties\":{\"evaluation_interval\":2,\"delay_evaluation\":6,\"slack_factor\":0.2}}', 'policy_config': '{\"name\":\"Bandit\",\"properties\":{\"evaluation_interval\":2,\"delay_evaluation\":6,\"slack_factor\":0.2}}', '_aml_system_generator_config': '{\"name\":\"RANDOM\",\"parameter_space\":{\"model\":[\"choice\",[[{\"grad_accumulation_step\":[\"choice\",[[1,2]]],\"learning_rate\":[\"uniform\",[0.005,0.05]],\"model_name\":[\"choice\",[[\"vitb16r224\"]]],\"number_of_epochs\":[\"choice\",[[15,30]]]},{\"train_crop_size\":[\"choice\",[[224,256]]],\"valid_crop_size\":[\"choice\",[[224,256]]],\"valid_resize_size\":[\"choice\",[[288,320,352]]],\"learning_rate\":[\"uniform\",[0.005,0.05]],\"model_name\":[\"choice\",[[\"seresnext\"]]]}]]]},\"properties\":null}', 'generator_config': '{\"name\":\"RANDOM\",\"parameter_space\":{\"model\":[\"choice\",[[{\"grad_accumulation_step\":[\"choice\",[[1,2]]],\"learning_rate\":[\"uniform\",[0.005,0.05]],\"model_name\":[\"choice\",[[\"vitb16r224\"]]],\"number_of_epochs\":[\"choice\",[[15,30]]]},{\"train_crop_size\":[\"choice\",[[224,256]]],\"valid_crop_size\":[\"choice\",[[224,256]]],\"valid_resize_size\":[\"choice\",[[288,320,352]]],\"learning_rate\":[\"uniform\",[0.005,0.05]],\"model_name\":[\"choice\",[[\"seresnext\"]]]}]]]},\"properties\":null}', '_aml_system_primary_metric_config': '{\"name\":\"iou\",\"goal\":\"maximize\"}', 'primary_metric_config': '{\"name\":\"iou\",\"goal\":\"maximize\"}', '_aml_system_platform_config': '{\"ServiceAddress\": \"https://westus2.api.azureml.ms\", \"SubscriptionId\": \"MY_SUBSCRIPTION\", \"ResourceGroupName\": \"MY_RESOURCEGROUP\", \"WorkspaceName\": \"MY_WORKSPACE\", \"ExperimentName\": \"chexpert-demo\", \"Definition\": {\"Configuration\": null, \"Attribution\": null, \"TelemetryValues\": {\"amlClientRequestId\": \"\", \"amlClientSessionId\": \"\", \"subscriptionId\": \"MY_SUBSCRIPTION\", \"maxConcurrentRuns\": 2, \"maxTotalRuns\": 10, \"tenantId\": \"\", \"maxDurationMinutes\": 60, \"samplingMethod\": \"RANDOM\", \"computeTarget\": \"ComputeTarget\"}, \"Overrides\": {\"Script\": \"hd_image_classification_multilabel_dnn_driver.py\", \"UseAbsolutePath\": false, \"Arguments\": [\"--data-folder\", \"$AZUREML_DATAREFERENCE_default\", \"--labels-file-root\", \"$AZUREML_DATAREFERENCE_labels_file_root\"], \"SourceDirectoryDataStore\": null, \"Framework\": 0, \"Target\": \"gpu-cluster\", \"DataReferences\": {}, \"Data\": {}, \"OutputData\": {}, \"Datacaches\": [], \"JobName\": null, \"MaxRunDurationSeconds\": null, \"NodeCount\": 1, \"InstanceTypes\": [], \"Priority\": null, \"CredentialPassthrough\": false, \"Identity\": null, \"Environment\": {\"Name\": \"AzureML-AutoML-DNN-Vision-GPU\", \"Version\": \"104\", \"AssetId\": \"azureml://registries/azureml/environments/AzureML-AutoML-DNN-Vision-GPU/versions/104\", \"AutoRebuild\": true, \"Python\": {\"InterpreterPath\": \"python\", \"UserManagedDependencies\": false, \"CondaDependencies\": {\"channels\": [\"conda-forge\", \"cerebis\"], \"dependencies\": [\"python=3.7\", \"pip=21.3.1\", \"numpy~=1.21.6\", \"libffi=3.3\", \"pycocotools=2.0.2\", \"shap=0.39.0\", \"recordclass=0.14.3\", \"llvmlite=0.36.0\", {\"pip\": [\"azureml-core==1.46.0\", \"azureml-mlflow==1.46.0\", \"azureml-dataset-runtime==1.46.0\", \"azureml-telemetry==1.46.0\", \"azureml-responsibleai==1.46.0\", \"azureml-automl-core==1.46.1.post1\", \"azureml-automl-runtime==1.46.1.post1\", \"azureml-train-automl-client==1.46.0\", \"azureml-defaults==1.46.0\", \"azureml-interpret==1.46.0\", \"azureml-train-automl-runtime==1.46.1.post1\", \"azureml-automl-dnn-vision==1.46.1\", \"azureml-dataprep>=2.24.4\"]}], \"name\": \"azureml_54a17edef71b712e10caf62b536f0b3b\"}, \"BaseCondaEnvironment\": null}, \"EnvironmentVariables\": {}, \"Docker\": {\"BaseImage\": \"mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.1-cudnn8-ubuntu18.04:20221010.v1\", \"Platform\": {\"Os\": \"Linux\", \"Architecture\": \"amd64\"}, \"BaseDockerfile\": null, \"BaseImageRegistry\": null, \"Enabled\": true, \"ShmSize\": \"16g\", \"Arguments\": []}, \"Spark\": {\"Repositories\": [], \"Packages\": [], \"PrecachePackages\": true}, \"InferencingStackVersion\": null}, \"History\": {\"OutputCollection\": true, \"DirectoriesToWatch\": null, \"EnableMLflowTracking\": false}, \"Spark\": {\"Configuration\": {}}, \"ParallelTask\": {\"MaxRetriesPerWorker\": 0, \"WorkerCountPerNode\": 1, \"TerminalExitCodes\": null, \"Configuration\": {}}, \"BatchAi\": {\"NodeCount\": 0}, \"AmlCompute\": {\"Name\": null, \"VmSize\": null, \"RetainCluster\": false, \"ClusterMaxNodeCount\": null}, \"AISuperComputer\": {\"InstanceType\": \"D2\", \"FrameworkImage\": null, \"ImageVersion\": null, \"Location\": null, \"AISuperComputerStorageData\": null, \"Interactive\": false, \"ScalePolicy\": null, \"VirtualClusterArmId\": null, \"TensorboardLogDirectory\": null, \"SSHPublicKey\": null, \"SSHPublicKeys\": null, \"EnableAzmlInt\": true, \"Priority\": \"Medium\", \"SLATier\": \"Standard\", \"UserAlias\": null}, \"KubernetesCompute\": {\"InstanceType\": null}, \"Tensorflow\": {\"WorkerCount\": 0, \"ParameterServerCount\": 0}, \"Mpi\": {\"ProcessCountPerNode\": 0}, \"PyTorch\": {\"CommunicationBackend\": null, \"ProcessCount\": null}, \"Hdi\": {\"YarnDeployMode\": 0}, \"ContainerInstance\": {\"Region\": null, \"CpuCores\": 2.0, \"MemoryGb\": 3.5}, \"ExposedPorts\": null, \"Docker\": {\"UseDocker\": null, \"SharedVolumes\": null, \"ShmSize\": null, \"Arguments\": null}, \"Cmk8sCompute\": {\"Configuration\": {}}, \"CommandReturnCodeConfig\": {\"ReturnCode\": 0, \"SuccessfulReturnCodes\": []}, \"EnvironmentVariables\": {\"AUTOML_SDK_RESOURCE_URL\": \"https://aka.ms/automl-resources/\"}, \"ApplicationEndpoints\": {}, \"Parameters\": []}, \"SnapshotId\": \"43bf3ae6-e5d6-4757-a27a-9cdfbde84824\", \"Snapshots\": [], \"SourceCodeDataReference\": null, \"ParentRunId\": null, \"DataContainerId\": null, \"RunType\": null, \"DisplayName\": null, \"EnvironmentAssetId\": null, \"Properties\": {}, \"Tags\": {}, \"AggregatedArtifactPath\": null}, \"ParentRunId\": \"gentle_carpet_grpm1rfbw3_HD\"}', 'platform_config': '{\"ServiceAddress\":\"https://westus2.api.azureml.ms\",\"SubscriptionId\":\"MY_SUBSCRIPTION\",\"ResourceGroupName\":\"MY_RESOURCEGROUP\",\"WorkspaceName\":\"MY_WORKSPACE\",\"ExperimentName\":\"chexpert-demo\",\"Definition\":{\"Configuration\":null,\"Attribution\":null,\"TelemetryValues\":{\"amlClientRequestId\":\"\",\"amlClientSessionId\":\"\",\"subscriptionId\":\"MY_SUBSCRIPTION\",\"maxConcurrentRuns\":2,\"maxTotalRuns\":10,\"tenantId\":\"\",\"maxDurationMinutes\":60,\"samplingMethod\":\"RANDOM\",\"computeTarget\":\"ComputeTarget\"},\"Overrides\":{\"Script\":\"hd_image_classification_multilabel_dnn_driver.py\",\"UseAbsolutePath\":false,\"Arguments\":[\"--data-folder\",\"$AZUREML_DATAREFERENCE_default\",\"--labels-file-root\",\"$AZUREML_DATAREFERENCE_labels_file_root\"],\"SourceDirectoryDataStore\":null,\"Framework\":0,\"Target\":\"gpu-cluster\",\"DataReferences\":{},\"Data\":{},\"OutputData\":{},\"Datacaches\":[],\"JobName\":null,\"MaxRunDurationSeconds\":null,\"NodeCount\":1,\"InstanceTypes\":[],\"Priority\":null,\"CredentialPassthrough\":false,\"Identity\":null,\"Environment\":{\"Name\":\"AzureML-AutoML-DNN-Vision-GPU\",\"Version\":\"104\",\"AssetId\":\"azureml://registries/azureml/environments/AzureML-AutoML-DNN-Vision-GPU/versions/104\",\"AutoRebuild\":true,\"Python\":{\"InterpreterPath\":\"python\",\"UserManagedDependencies\":false,\"CondaDependencies\":{\"channels\":[\"conda-forge\",\"cerebis\"],\"dependencies\":[\"python=3.7\",\"pip=21.3.1\",\"numpy~=1.21.6\",\"libffi=3.3\",\"pycocotools=2.0.2\",\"shap=0.39.0\",\"recordclass=0.14.3\",\"llvmlite=0.36.0\",{\"pip\":[\"azureml-core==1.46.0\",\"azureml-mlflow==1.46.0\",\"azureml-dataset-runtime==1.46.0\",\"azureml-telemetry==1.46.0\",\"azureml-responsibleai==1.46.0\",\"azureml-automl-core==1.46.1.post1\",\"azureml-automl-runtime==1.46.1.post1\",\"azureml-train-automl-client==1.46.0\",\"azureml-defaults==1.46.0\",\"azureml-interpret==1.46.0\",\"azureml-train-automl-runtime==1.46.1.post1\",\"azureml-automl-dnn-vision==1.46.1\",\"azureml-dataprep>=2.24.4\"]}],\"name\":\"azureml_54a17edef71b712e10caf62b536f0b3b\"},\"BaseCondaEnvironment\":null},\"EnvironmentVariables\":{},\"Docker\":{\"BaseImage\":\"mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.1-cudnn8-ubuntu18.04:20221010.v1\",\"Platform\":{\"Os\":\"Linux\",\"Architecture\":\"amd64\"},\"BaseDockerfile\":null,\"BaseImageRegistry\":null,\"Enabled\":true,\"ShmSize\":\"16g\",\"Arguments\":[]},\"Spark\":{\"Repositories\":[],\"Packages\":[],\"PrecachePackages\":true},\"InferencingStackVersion\":null},\"History\":{\"OutputCollection\":true,\"DirectoriesToWatch\":null,\"EnableMLflowTracking\":false},\"Spark\":{\"Configuration\":{}},\"ParallelTask\":{\"MaxRetriesPerWorker\":0,\"WorkerCountPerNode\":1,\"TerminalExitCodes\":null,\"Configuration\":{}},\"BatchAi\":{\"NodeCount\":0},\"AmlCompute\":{\"Name\":null,\"VmSize\":null,\"RetainCluster\":false,\"ClusterMaxNodeCount\":null},\"AISuperComputer\":{\"InstanceType\":\"D2\",\"FrameworkImage\":null,\"ImageVersion\":null,\"Location\":null,\"AISuperComputerStorageData\":null,\"Interactive\":false,\"ScalePolicy\":null,\"VirtualClusterArmId\":null,\"TensorboardLogDirectory\":null,\"SSHPublicKey\":null,\"SSHPublicKeys\":null,\"EnableAzmlInt\":true,\"Priority\":\"Medium\",\"SLATier\":\"Standard\",\"UserAlias\":null},\"KubernetesCompute\":{\"InstanceType\":null},\"Tensorflow\":{\"WorkerCount\":0,\"ParameterServerCount\":0},\"Mpi\":{\"ProcessCountPerNode\":0},\"PyTorch\":{\"CommunicationBackend\":null,\"ProcessCount\":null},\"Hdi\":{\"YarnDeployMode\":0},\"ContainerInstance\":{\"Region\":null,\"CpuCores\":2.0,\"MemoryGb\":3.5},\"ExposedPorts\":null,\"Docker\":{\"UseDocker\":null,\"SharedVolumes\":null,\"ShmSize\":null,\"Arguments\":null},\"Cmk8sCompute\":{\"Configuration\":{}},\"CommandReturnCodeConfig\":{\"ReturnCode\":0,\"SuccessfulReturnCodes\":[]},\"EnvironmentVariables\":{\"AUTOML_SDK_RESOURCE_URL\":\"https://aka.ms/automl-resources/\"},\"ApplicationEndpoints\":{},\"Parameters\":[]},\"SnapshotId\":\"43bf3ae6-e5d6-4757-a27a-9cdfbde84824\",\"Snapshots\":[],\"SourceCodeDataReference\":null,\"ParentRunId\":null,\"DataContainerId\":null,\"RunType\":null,\"DisplayName\":null,\"EnvironmentAssetId\":null,\"Properties\":{},\"Tags\":{},\"AggregatedArtifactPath\":null},\"ParentRunId\":\"gentle_carpet_grpm1rfbw3_HD\"}', '_aml_system_resume_child_runs': 'null', 'resume_child_runs': 'null', '_aml_system_all_jobs_generated': 'true', 'all_jobs_generated': 'true', '_aml_system_cancellation_requested': 'false', '_aml_system_progress_metadata_evaluation_timestamp': '\"2022-11-18T00:35:55.684413\"', '_aml_system_progress_metadata_digest': '\"404e8521cbdaa14ccfd6335460ef4c539cc7027a517262c67d0602f30924f7fc\"', '_aml_system_progress_metadata_active_timestamp': '\"2022-11-18T00:35:55.684413\"', '_aml_system_optimizer_state_artifact': 'null', '_aml_system_outdated_optimizer_state_artifacts': '\"[]\"', '_aml_system_gentle_carpet_grpm1rfbw3_HD_0': '{\"model\": {\"grad_accumulation_step\": 2, \"learning_rate\": 0.029601861139555583, \"model_name\": \"vitb16r224\", \"number_of_epochs\": 15}}', 'gentle_carpet_grpm1rfbw3_HD_0': '{\"model\": {\"grad_accumulation_step\": 2, \"learning_rate\": 0.029601861139555583, \"model_name\": \"vitb16r224\", \"number_of_epochs\": 15}}', '_aml_system_gentle_carpet_grpm1rfbw3_HD_1': '{\"model\": {\"learning_rate\": 0.03571392815124247, \"model_name\": \"seresnext\", \"train_crop_size\": 256, \"valid_crop_size\": 224, \"valid_resize_size\": 288}}', 'gentle_carpet_grpm1rfbw3_HD_1': '{\"model\": {\"learning_rate\": 0.03571392815124247, \"model_name\": \"seresnext\", \"train_crop_size\": 256, \"valid_crop_size\": 224, \"valid_resize_size\": 288}}', '_aml_system_gentle_carpet_grpm1rfbw3_HD_1_cancelled': 'true', '_aml_system_gentle_carpet_grpm1rfbw3_HD_2': '{\"model\": {\"grad_accumulation_step\": 1, \"learning_rate\": 0.025906770087909987, \"model_name\": \"vitb16r224\", \"number_of_epochs\": 15}}', 'gentle_carpet_grpm1rfbw3_HD_2': '{\"model\": {\"grad_accumulation_step\": 1, \"learning_rate\": 0.025906770087909987, \"model_name\": \"vitb16r224\", \"number_of_epochs\": 15}}', '_aml_system_gentle_carpet_grpm1rfbw3_HD_3': '{\"model\": {\"learning_rate\": 0.024612312563466528, \"model_name\": \"seresnext\", \"train_crop_size\": 256, \"valid_crop_size\": 256, \"valid_resize_size\": 352}}', 'gentle_carpet_grpm1rfbw3_HD_3': '{\"model\": {\"learning_rate\": 0.024612312563466528, \"model_name\": \"seresnext\", \"train_crop_size\": 256, \"valid_crop_size\": 256, \"valid_resize_size\": 352}}', '_aml_system_gentle_carpet_grpm1rfbw3_HD_2_cancelled': 'true', '_aml_system_gentle_carpet_grpm1rfbw3_HD_4': '{\"model\": {\"grad_accumulation_step\": 1, \"learning_rate\": 0.030437243789875296, \"model_name\": \"vitb16r224\", \"number_of_epochs\": 30}}', 'gentle_carpet_grpm1rfbw3_HD_4': '{\"model\": {\"grad_accumulation_step\": 1, \"learning_rate\": 0.030437243789875296, \"model_name\": \"vitb16r224\", \"number_of_epochs\": 30}}', '_aml_system_gentle_carpet_grpm1rfbw3_HD_3_cancelled': 'true', '_aml_system_gentle_carpet_grpm1rfbw3_HD_5': '{\"model\": {\"grad_accumulation_step\": 2, \"learning_rate\": 0.04336274069357673, \"model_name\": \"vitb16r224\", \"number_of_epochs\": 15}}', 'gentle_carpet_grpm1rfbw3_HD_5': '{\"model\": {\"grad_accumulation_step\": 2, \"learning_rate\": 0.04336274069357673, \"model_name\": \"vitb16r224\", \"number_of_epochs\": 15}}', '_aml_system_gentle_carpet_grpm1rfbw3_HD_5_cancelled': 'true', '_aml_system_gentle_carpet_grpm1rfbw3_HD_6': '{\"model\": {\"learning_rate\": 0.013904556575140989, \"model_name\": \"seresnext\", \"train_crop_size\": 256, \"valid_crop_size\": 256, \"valid_resize_size\": 288}}', 'gentle_carpet_grpm1rfbw3_HD_6': '{\"model\": {\"learning_rate\": 0.013904556575140989, \"model_name\": \"seresnext\", \"train_crop_size\": 256, \"valid_crop_size\": 256, \"valid_resize_size\": 288}}', '_aml_system_gentle_carpet_grpm1rfbw3_HD_7': '{\"model\": {\"grad_accumulation_step\": 2, \"learning_rate\": 0.025775866851645842, \"model_name\": \"vitb16r224\", \"number_of_epochs\": 30}}', 'gentle_carpet_grpm1rfbw3_HD_7': '{\"model\": {\"grad_accumulation_step\": 2, \"learning_rate\": 0.025775866851645842, \"model_name\": \"vitb16r224\", \"number_of_epochs\": 30}}', '_aml_system_gentle_carpet_grpm1rfbw3_HD_6_cancelled': 'true', '_aml_system_gentle_carpet_grpm1rfbw3_HD_8': '{\"model\": {\"grad_accumulation_step\": 1, \"learning_rate\": 0.04015489201810051, \"model_name\": \"vitb16r224\", \"number_of_epochs\": 15}}', 'gentle_carpet_grpm1rfbw3_HD_8': '{\"model\": {\"grad_accumulation_step\": 1, \"learning_rate\": 0.04015489201810051, \"model_name\": \"vitb16r224\", \"number_of_epochs\": 15}}', '_aml_system_gentle_carpet_grpm1rfbw3_HD_9': '{\"model\": {\"learning_rate\": 0.03996506667044554, \"model_name\": \"seresnext\", \"train_crop_size\": 256, \"valid_crop_size\": 256, \"valid_resize_size\": 352}}', 'gentle_carpet_grpm1rfbw3_HD_9': '{\"model\": {\"learning_rate\": 0.03996506667044554, \"model_name\": \"seresnext\", \"train_crop_size\": 256, \"valid_crop_size\": 256, \"valid_resize_size\": 352}}', '_aml_system_gentle_carpet_grpm1rfbw3_HD_8_cancelled': 'true', '_aml_system_final_best_metric_update_retry_count': '1', '_aml_system_automl_is_child_run_end_telemetry_event_logged': 'True'}, 'properties': {'_aml_system_scenario_identification': 'Remote.Child', 'iteration': '0', 'primary_metric_config': '{\"name\":\"iou\",\"goal\":\"maximize\"}', 'resume_from': 'null', 'runTemplate': 'HyperDrive', 'azureml.runsource': 'hyperdrive', 'platform': 'AML', 'ContentSnapshotId': '43bf3ae6-e5d6-4757-a27a-9cdfbde84824', 'user_agent': 'jasmine/c2231e359abf0fb7d62e74e03cb1302a18d8abd7', 'debug_flag': '{\"custom_optimizer_url\":null,\"custom_logger_url\":null,\"optimizer_settings\":null,\"priors\":null,\"early_failure_threshold\":null}', 'space_size': 'infinite_space_size', 'score': '0.47895', 'best_child_run_id': 'gentle_carpet_grpm1rfbw3_HD_0', 'best_metric_status': 'Succeeded', 'best_data_container_id': 'dcid.gentle_carpet_grpm1rfbw3_HD_0'}, 'id': '/subscriptions/MY_SUBSCRIPTION/resourceGroups/MY_RESOURCEGROUP/providers/Microsoft.MachineLearningServices/workspaces/MY_WORKSPACE/jobs/gentle_carpet_grpm1rfbw3_HD', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/demo6/code/Users/medical-imaging/notebooks', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7f5bbc2ddc00>, 'serialize': <msrest.serialization.Serializer object at 0x7f5bac22a6b0>, 'sampling_algorithm': <azure.ai.ml.entities._job.sweep.sampling_algorithm.RandomSamplingAlgorithm object at 0x7f5bac17f310>, 'early_termination': <azure.ai.ml.entities._job.sweep.early_termination_policy.BanditPolicy object at 0x7f5bae2de410>, 'limits': <azure.ai.ml.entities._job.job_limits.SweepJobLimits object at 0x7f5bac22b760>, 'search_space': {'model': <azure.ai.ml.entities._job.sweep.search_space.Choice object at 0x7f5bbc2dde40>}, 'objective': <azure.ai.ml._restclient.v2022_10_01_preview.models._models_py3.Objective object at 0x7f5bac229390>, 'display_name': 'boring_office_3jm8j65q', 'experiment_name': 'chexpert-demo', 'compute': 'gpu-cluster', 'services': {'Studio': <azure.ai.ml._restclient.v2022_10_01_preview.models._models_py3.JobService object at 0x7f5bac22ba90>}, 'inputs': {}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.gentle_carpet_grpm1rfbw3_HD_0', 'mode': 'rw_mount'}}, 'trial': <azure.ai.ml.entities._job.parameterized_command.ParameterizedCommand object at 0x7f5bbc2dea40>, 'identity': None})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hd_job = ml_client.jobs.get(returned_job.name + \"_HD\")\n",
        "hd_job"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Results using 'small CheXpert' dataset\n",
        "\n",
        "These are some of the charts from the experiments we have run when preparing this tutorial. You should get something similar.\n",
        "\n",
        "<img src=\"images/dp-chexpert_small-runs.png\" width=1200 />\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Bonus\n",
        "\n",
        "### Results using standard (non-resized) CheXpert dataset\n",
        "\n",
        "We show results of training CheXpert using the standard image size. The two graphs below show overall performance using a 'serexnet' model. In this case, we performed an exhaustive evaluation using by disabling the early terminal policy (configuration parameters are below). \n",
        "\n",
        "You can reproduce results by just downloading/unziping standard CheXpert dataset using the steps above and using the configuration settings below. \n",
        "\n",
        "<img src=\"images/dp-chexpert-runs.png\" width=800 >\n",
        "\n",
        "<img src=\"images/dp-chexpert-runs_parallel_coordinates_chart.png\" width=800 >"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Effect of [hyperparameters](https://learn.microsoft.com/en-us/azure/machine-learning/reference-automl-images-hyperparameters#image-classification-multi-class-and-multi-label-specific-hyperparameters)\n",
        "\n",
        "We can easily visualize the effects of hyperparameters. The two graphs below show effect of learning rate and weighted loss with respect to the AUC macro (metric). Based on the graphs below, we osbserve that performance (AUC Macro) increases for:\n",
        "\n",
        "1. Larger learning rates (greater than 0.001) \n",
        "2. Weighted loss with sqrt. (class_weights), which corresponds to value 1 (value 2 corresponds to weighted loss with class_weights).\n",
        "\n",
        "<img src=\"images/dp-chexpert-scatter-AUC_lr.png\" width=800 >\n",
        "\n",
        "<img src=\"images/dp-chexpert-scatter-AUC_wl.png\" width=800 >\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion\n",
        "\n",
        "This tutorial has demonstrated the feasibility of low-code solution that is AutoML to achieve state-of-the-art performance on a radiological image classification task. Good luck with your experiments!"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK V2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "e4cce46d6be9934fbd27f9ca0432556941ea5bdf741d4f4d64c6cd7f8dfa8fba"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
